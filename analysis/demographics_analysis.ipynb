{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743d92d6-3bb9-416b-afe8-decb8ac06682",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h_/pm5z54tn7rj170br8494ljz80000gn/T/ipykernel_65361/1060765235.py:29: DtypeWarning: Columns (254,255,256,257,258,259) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('pilot_total_clean_quest_updated.csv')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "# import moss\n",
    "import csv\n",
    "import random\n",
    "%matplotlib inline\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import mixedlm\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from matplotlib.cm import get_cmap\n",
    "from plot_utils import combined_rolling_average_and_model_fit, combined_sliding_window_and_model_fit_split_col\n",
    "from common_functions import remove_unit_variance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df = pd.read_csv('pilot_total_clean_quest_updated.csv')\n",
    "numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "# df_cleaned = pd.read_csv('pilot_total_errors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bc23ec8-e379-431e-8fde-1af78df85e5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'op' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m home_dir \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mabspath(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m parent_dir \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mdirname(home_dir)\n\u001b[1;32m      5\u001b[0m file_path \u001b[38;5;241m=\u001b[39m op\u001b[38;5;241m.\u001b[39mjoin(parent_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdemographics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'op' is not defined"
     ]
    }
   ],
   "source": [
    "home_dir = op.abspath('./')\n",
    "\n",
    "parent_dir = op.dirname(home_dir)\n",
    "\n",
    "file_path = op.join(parent_dir, 'data', 'demographics.csv')\n",
    "\n",
    "questionnaires = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db33be7d-3b1b-4433-891e-5e23155d57ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "questionnaires['StartDate'] = pd.to_datetime(\n",
    "    questionnaires['StartDate'], \n",
    "    format='%Y-%m-%d %H:%M:%S', \n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "# Remove invalid dates and filter\n",
    "questionnaires = questionnaires.dropna(subset=['StartDate'])\n",
    "pilot5 = questionnaires[\n",
    "    (questionnaires['StartDate'] >= '2024-10-08') & \n",
    "    (questionnaires['StartDate'] <= '2024-10-30')\n",
    "]\n",
    "\n",
    "pilot6 = questionnaires[\n",
    "    (questionnaires['StartDate'] >= '2024-11-22') & \n",
    "    (questionnaires['StartDate'] <= '2025-01-30')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56b6f630-ff1b-4f60-85a1-16e02cf413ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "### pilot5 '2024-10-08', '2024-10-30'\n",
    "### pilot6 '2024-11-22', '2025-01-30'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39498e87-892f-4c4d-9613-4bfa80af9769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>DistributionChannel</th>\n",
       "      <th>UserLanguage</th>\n",
       "      <th>Q1</th>\n",
       "      <th>BOR</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1500</th>\n",
       "      <td>2024-11-22 23:54:48</td>\n",
       "      <td>2024-11-22 23:56:40</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-22 23:56:41</td>\n",
       "      <td>R_3AYD67rz2zrQbgo</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>10/18/2003</td>\n",
       "      <td>2,6</td>\n",
       "      <td>1</td>\n",
       "      <td>141181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>2024-11-23 00:24:25</td>\n",
       "      <td>2024-11-23 00:26:31</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-23 00:26:32</td>\n",
       "      <td>R_1QRR55txOCGFEfI</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>12/26/2003</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>166588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1502</th>\n",
       "      <td>2024-11-23 17:23:09</td>\n",
       "      <td>2024-11-23 17:25:31</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-23 17:25:32</td>\n",
       "      <td>R_5R4UcEFdKO8nYFH</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>12/27/2005</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>168691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1503</th>\n",
       "      <td>2024-11-24 00:19:03</td>\n",
       "      <td>2024-11-24 00:20:56</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-24 00:20:57</td>\n",
       "      <td>R_7xBxRelclqvl2hz</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>09/06/2004</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>145849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>2024-11-24 12:49:02</td>\n",
       "      <td>2024-11-24 12:50:16</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>2024-11-24 12:50:17</td>\n",
       "      <td>R_1B9UyonAgDcJNtU</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>11/08/2004</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>167875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1902</th>\n",
       "      <td>2025-01-28 19:59:01</td>\n",
       "      <td>2025-01-28 23:29:01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12600</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-04 23:29:08</td>\n",
       "      <td>R_6PemmLv907dxuNr</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>171031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1903</th>\n",
       "      <td>2025-01-29 19:21:05</td>\n",
       "      <td>2025-01-29 19:23:14</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>129</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-05 19:23:14</td>\n",
       "      <td>R_70rp5L9kWTHnUNX</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>161086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1904</th>\n",
       "      <td>2025-01-29 20:13:55</td>\n",
       "      <td>2025-01-29 20:14:47</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-05 20:14:53</td>\n",
       "      <td>R_54l2LukOFB8na7r</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>145420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>2025-01-29 21:40:59</td>\n",
       "      <td>2025-01-29 21:47:18</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>379</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-05 21:47:22</td>\n",
       "      <td>R_5h5YHmsVQMIS4en</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>127165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>2025-01-29 22:08:08</td>\n",
       "      <td>2025-01-29 22:08:34</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-02-05 22:08:40</td>\n",
       "      <td>R_6fx07AiGYxlJNUn</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>EN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>138529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>407 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               StartDate              EndDate Status Progress  \\\n",
       "1500 2024-11-22 23:54:48  2024-11-22 23:56:40      0      100   \n",
       "1501 2024-11-23 00:24:25  2024-11-23 00:26:31      0      100   \n",
       "1502 2024-11-23 17:23:09  2024-11-23 17:25:31      0      100   \n",
       "1503 2024-11-24 00:19:03  2024-11-24 00:20:56      0      100   \n",
       "1504 2024-11-24 12:49:02  2024-11-24 12:50:16      0      100   \n",
       "...                  ...                  ...    ...      ...   \n",
       "1902 2025-01-28 19:59:01  2025-01-28 23:29:01      0        0   \n",
       "1903 2025-01-29 19:21:05  2025-01-29 19:23:14      0       21   \n",
       "1904 2025-01-29 20:13:55  2025-01-29 20:14:47      0       57   \n",
       "1905 2025-01-29 21:40:59  2025-01-29 21:47:18      0       29   \n",
       "1906 2025-01-29 22:08:08  2025-01-29 22:08:34      0       29   \n",
       "\n",
       "     Duration (in seconds) Finished         RecordedDate         ResponseId  \\\n",
       "1500                   112        1  2024-11-22 23:56:41  R_3AYD67rz2zrQbgo   \n",
       "1501                   126        1  2024-11-23 00:26:32  R_1QRR55txOCGFEfI   \n",
       "1502                   141        1  2024-11-23 17:25:32  R_5R4UcEFdKO8nYFH   \n",
       "1503                   113        1  2024-11-24 00:20:57  R_7xBxRelclqvl2hz   \n",
       "1504                    74        1  2024-11-24 12:50:17  R_1B9UyonAgDcJNtU   \n",
       "...                    ...      ...                  ...                ...   \n",
       "1902                 12600        0  2025-02-04 23:29:08  R_6PemmLv907dxuNr   \n",
       "1903                   129        0  2025-02-05 19:23:14  R_70rp5L9kWTHnUNX   \n",
       "1904                    51        0  2025-02-05 20:14:53  R_54l2LukOFB8na7r   \n",
       "1905                   379        0  2025-02-05 21:47:22  R_5h5YHmsVQMIS4en   \n",
       "1906                    25        0  2025-02-05 22:08:40  R_6fx07AiGYxlJNUn   \n",
       "\n",
       "     DistributionChannel UserLanguage Q1  BOR Q22  Q34   Q5     Q25  \\\n",
       "1500           anonymous           EN  1  NaN   1    2    1  female   \n",
       "1501           anonymous           EN  1  NaN   1  NaN    1  female   \n",
       "1502           anonymous           EN  1  NaN   1    2    1  female   \n",
       "1503           anonymous           EN  1  NaN   1    2    1  female   \n",
       "1504           anonymous           EN  1  NaN   1  NaN    1  female   \n",
       "...                  ...          ... ..  ...  ..  ...  ...     ...   \n",
       "1902           anonymous           EN  1  NaN   1  NaN  NaN     NaN   \n",
       "1903           anonymous           EN  1  NaN   1  NaN  NaN     NaN   \n",
       "1904           anonymous           EN  1  NaN   1  NaN    2     NaN   \n",
       "1905           anonymous           EN  1  NaN   1  NaN  NaN     NaN   \n",
       "1906           anonymous           EN  1  NaN   1  NaN  NaN     NaN   \n",
       "\n",
       "             Q26  Q27  Q28      id  \n",
       "1500  10/18/2003  2,6    1  141181  \n",
       "1501  12/26/2003    2    2  166588  \n",
       "1502  12/27/2005    3    2  168691  \n",
       "1503  09/06/2004    2    2  145849  \n",
       "1504  11/08/2004    5    1  167875  \n",
       "...          ...  ...  ...     ...  \n",
       "1902         NaN  NaN  NaN  171031  \n",
       "1903         NaN  NaN  NaN  161086  \n",
       "1904         NaN  NaN  NaN  145420  \n",
       "1905         NaN  NaN  NaN  127165  \n",
       "1906         NaN  NaN  NaN  138529  \n",
       "\n",
       "[407 rows x 20 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilot6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dac1f04-5709-417e-a438-721f024d8abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = op.abspath('./')\n",
    "\n",
    "data_files = glob.glob(op.join(home_dir,\n",
    "                        'data',\n",
    "                        '*.csv'))\n",
    "sns.set_context('talk')\n",
    "\n",
    "def df_creation(data_files, start_date, end_date):\n",
    "    processed_dfs = []\n",
    "    date_column = 'date'\n",
    "\n",
    "    for file_path in data_files:\n",
    "        try:\n",
    "            temp_df = pd.read_csv(file_path)\n",
    "            temp_df['filename'] = file_path\n",
    "            processed_dfs.append(temp_df)\n",
    "        except Exception as e:\n",
    "            \n",
    "            continue\n",
    "\n",
    "    if processed_dfs:\n",
    "        df = pd.concat(processed_dfs, ignore_index=True)\n",
    "        df[date_column] = pd.to_datetime(df[date_column], format='%Y-%m-%d_%Hh%M.%S.%f', errors='coerce')\n",
    "        df.dropna(subset=[date_column], inplace=True)\n",
    "        df = df[(df[date_column] >= pd.to_datetime(start_date)) & (df[date_column] <= pd.to_datetime(end_date))]\n",
    "        \n",
    "        # # Uncomment and adapt the following lines as needed:\n",
    "        # df = df.loc[df['V2_diff'].notnull()].reset_index(drop=True)\n",
    "        # df['reliability'] = df['reliability'].astype(float)\n",
    "        # df['Retrocue Reliability'] = np.where(df['reliability'] > 0.75, 'high', 'low')\n",
    "        # non_numeric_values = df['resp_correct'][~df['resp_correct'].apply(np.isreal)]\n",
    "        # numeric_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "        # result = df[numeric_columns].groupby('participant').mean()\n",
    "        \n",
    "        \n",
    "\n",
    "    else:\n",
    "        # Return an empty DataFrame if no files were processed successfully\n",
    "        df = pd.DataFrame()\n",
    "    \n",
    "    return df, numeric_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53753481-94cc-4c99-a505-2c130b364fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pilot5, numeric_columns = df_creation(data_files,'2024-10-08', '2024-10-30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8cff947-5cbc-41a1-a3f1-222ec3a66b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pilot6, numeric_columns = df_creation(data_files,'2024-11-22', '2025-01-30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8be85b1-551b-4e8f-ae67-bc0019c0b1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_pilot5['participant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a92d8583-a322-44cb-9955-6f2cad79f103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(df_pilot6['participant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01141728-5aee-42a1-9e87-78484e41d94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_pilot5 = df[df['pilot_number'] == 1]\n",
    "len(set(df_filtered_pilot5['participant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "036ee76e-05e8-4283-a2d5-c46fb7d352a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filtered_pilot6 = df[df['pilot_number'] == 2]\n",
    "len(set(df_filtered_pilot6['participant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7464fa73-4fbb-4d60-9266-158ca8628f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_participants_pilot5 = df_filtered_pilot5['participant'].unique()\n",
    "len(unique_participants_pilot5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c4b6bd2-3018-4e63-9142-3b5744e3a30f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_participants_pilot6 = df_filtered_pilot6['participant'].unique()\n",
    "len(unique_participants_pilot6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05c435c8-b008-4e46-93fe-1b1e4e9b0c8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>DistributionChannel</th>\n",
       "      <th>UserLanguage</th>\n",
       "      <th>Q1</th>\n",
       "      <th>BOR</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [StartDate, EndDate, Status, Progress, Duration (in seconds), Finished, RecordedDate, ResponseId, DistributionChannel, UserLanguage, Q1, BOR, Q22, Q34, Q5, Q25, Q26, Q27, Q28, id]\n",
       "Index: []"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_rows = questionnaires[questionnaires['id'].isin(unique_participants_pilot5)]\n",
    "matched_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c092b4f-ec05-4ec9-a801-5ac36702ec25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartDate</th>\n",
       "      <th>EndDate</th>\n",
       "      <th>Status</th>\n",
       "      <th>Progress</th>\n",
       "      <th>Duration (in seconds)</th>\n",
       "      <th>Finished</th>\n",
       "      <th>RecordedDate</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>DistributionChannel</th>\n",
       "      <th>UserLanguage</th>\n",
       "      <th>Q1</th>\n",
       "      <th>BOR</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [StartDate, EndDate, Status, Progress, Duration (in seconds), Finished, RecordedDate, ResponseId, DistributionChannel, UserLanguage, Q1, BOR, Q22, Q34, Q5, Q25, Q26, Q27, Q28, id]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matched_rows = questionnaires[questionnaires['id'].isin(unique_participants_pilot6)]\n",
    "matched_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45ebbd29-2a4e-441c-b731-5af306af0188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_participants_pilot6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2a804d6-1367-4116-ac54-3f0d753f4d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match participants and keep only the first entry for each\n",
    "matched_rows_pilot5 = questionnaires[questionnaires['id'].astype(int).isin(unique_participants_pilot5)]\n",
    "filtered_demo_pilot5 = matched_rows_pilot5.drop_duplicates(subset=['id'], keep='first')\n",
    "\n",
    "matched_rows_pilot6 = questionnaires[questionnaires['id'].astype(int).isin(unique_participants_pilot6)]\n",
    "filtered_demo_pilot6 = matched_rows_pilot6.drop_duplicates(subset=['id'], keep='first')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d4b8b8b9-ed79-4360-b093-9e39f501d24a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['female', nan, 'male', 'decline', 'female ', 'Male', 'Female',\n",
       "       'non-binary', 'Female ', 'f', 'deline'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_demo_pilot5['Q25'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f04fb254-0181-4856-ac1d-38996d2caf70",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q25\n",
       "female        78\n",
       "male          22\n",
       "decline        4\n",
       "Female         4\n",
       "Male           4\n",
       "female         3\n",
       "nonbinary      1\n",
       "femaile        1\n",
       "non binary     1\n",
       "male           1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q25_counts_pilot6 = filtered_demo_pilot6['Q25'].value_counts()\n",
    "q25_counts_pilot6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f0339277-3a71-475f-ad7a-d4107c2d6f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "119"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q25_counts_pilot6 = filtered_demo_pilot6['Q25'].value_counts()\n",
    "q25_counts_pilot6.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "888f4e48-d9a5-4928-932e-4c57d242962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# female - 97\n",
    "# male - 28\n",
    "# decline - 9\n",
    "# non binary - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3961b05c-74a4-49c0-bdc5-8e8f67332b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# female -108\n",
    "# male - 17\n",
    "# nonbinary - 3\n",
    "# declined - 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6dcc6736-446b-46df-ba83-386f241453f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['6/19/2003', 'decline', nan, '08/25/2003', '01/14/2005',\n",
       "       '12/11/2002', 'January 17, 2005', '11/01/2004', '05/07/2004',\n",
       "       '02/16/2005', '06/19/2005', '08/21/02', '04/17/2004', '03/03/2004',\n",
       "       '03/18/2004', '09/06/2004', '10/26/2005', '11/07/2003',\n",
       "       '08/16/2005', '04/11/2003', '12/12/2005', '10/18/2003',\n",
       "       '06/13/2004', '12/15/2003', '11/06/2004', 'May 28th, 20004',\n",
       "       '01/09/2004', '02/12/2005', '18 JAN 2024', '4 May 2005',\n",
       "       '03/16/2003', '06/03/2000', '9/1/2004', '10/24/2003',\n",
       "       'May 5th 2004', '04/28/2004', '8/28/2006', 'March 22, 2004',\n",
       "       '01/18/2003', '01/30/2004', '09/15/2003', '10/29/2005', '09/06/04',\n",
       "       '5/21/2005', '12/26/2003', '10/26/2004', 'Decline', '04/08/2005',\n",
       "       '07/25/2006', '01/25/2003', '12/17/2002', '07/15/2003',\n",
       "       '11/12/1991', '1//12/05', 'Feb/4/2002', '8/3/2005', '8/24/2005',\n",
       "       '12/13/2004', '01-28-2003', '10/12/2004', '12/24/2003',\n",
       "       '12/23/2002', '01/27/2004', '09/18/1999', '04262005', '01/30/2005',\n",
       "       '08/28/03', '10/13/2003', '09/27/2004', '08/07/2003', '9/17/2003',\n",
       "       '06/08/2005', '09/06/2003', '06/11/2005', '03/19/05', '10/07/2003',\n",
       "       '03/28/2003', '12/21/2002', '03/02/1993', '10/5/2006',\n",
       "       '03-03-2005', '02/15/2001', '01/11/2005', '11/12/2003', '2005',\n",
       "       '2003', '07/27/2005', 'April 1, 2004', '10/18/2004', '06/16/2003',\n",
       "       '06/09/04', '6/23/2003', '12/25/2003', '12/09/2002', '01/12/2002',\n",
       "       '10/21/2003', '09/12/2006', '10/20/2004', '01/04/2004',\n",
       "       '12/27/2004', '06-08-2004', '09/20/2005', '09/27/2003',\n",
       "       'October 16, 2006', '08/15/2005'], dtype=object)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_demo_pilot5['Q26'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "379bb786-0ab1-427b-a041-912346bed384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PILOT 5 RESULTS\n",
      "============================================================\n",
      "Found 1 participant(s) under 2 years old - excluding from analysis:\n",
      "          id          Q26    Q26_clean birth_date           StartDate      age\n",
      "1164  138742  18 JAN 2024  18 JAN 2024 2024-01-18 2024-10-14 15:42:02  0.73922\n",
      "Total responses: 134\n",
      "Valid birth dates parsed: 111\n",
      "Valid start dates: 134\n",
      "Failed to parse birth dates: 1\n",
      "Declined or missing birth dates: 22\n",
      "Missing start dates: 0\n",
      "\n",
      "Age Statistics (excluding 1-year-old outlier) (n = 110):\n",
      "Mean age: 20.7 years\n",
      "SD: 2.0\n",
      "Range: 18–33\n",
      "\n",
      "Demographic format:\n",
      "(M age = 20.7 years, SD = 2.0, range = 18–33)\n",
      "\n",
      "Problematic birth date entries:\n",
      "['04262005']\n",
      "\n",
      "============================================================\n",
      "PILOT 6 RESULTS\n",
      "============================================================\n",
      "Total responses: 136\n",
      "Valid birth dates parsed: 110\n",
      "Valid start dates: 136\n",
      "Failed to parse birth dates: 0\n",
      "Declined or missing birth dates: 26\n",
      "Missing start dates: 0\n",
      "\n",
      "Age Statistics (n = 110):\n",
      "Mean age: 20.7 years\n",
      "SD: 2.2\n",
      "Range: 18–35\n",
      "\n",
      "Demographic format:\n",
      "(M age = 20.7 years, SD = 2.2, range = 18–35)\n",
      "\n",
      "============================================================\n",
      "SUMMARY\n",
      "============================================================\n",
      "Pilot 5: 110 valid ages from 134 responses\n",
      "Pilot 6: 110 valid ages from 136 responses\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def process_birth_dates_with_start_dates(df, q26_column='Q26'):\n",
    "    \"\"\"\n",
    "    Process birth dates and convert to ages using StartDate column in the same dataframe\n",
    "    \n",
    "    Parameters:\n",
    "    df: DataFrame containing both birth dates (Q26) and StartDate columns\n",
    "    q26_column: Name of the column containing birth dates (default 'Q26')\n",
    "    \n",
    "    Returns:\n",
    "    Dictionary with results and processed DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    \n",
    "    # Clean invalid responses\n",
    "    invalid_responses = ['decline', 'Decline', 'nan', '']\n",
    "    df_copy['Q26_clean'] = df_copy[q26_column].replace(invalid_responses, pd.NA)\n",
    "    \n",
    "    # Fix common typos and format issues\n",
    "    df_copy['Q26_clean'] = df_copy['Q26_clean'].str.replace('20004', '2004')\n",
    "    df_copy['Q26_clean'] = df_copy['Q26_clean'].str.replace('1//12/05', '1/12/05')\n",
    "    df_copy['Q26_clean'] = df_copy['Q26_clean'].str.replace('08212004', '08/21/2004')\n",
    "    \n",
    "    def parse_birth_dates(date_series):\n",
    "        \"\"\"Parse birth dates with multiple format attempts\"\"\"\n",
    "        formats = [\n",
    "            '%m/%d/%Y',      # 6/19/2003\n",
    "            '%m/%d/%y',      # 08/21/02, 05/18/06\n",
    "            '%Y/%m/%d',      # 2005/01/15\n",
    "            '%m-%d-%Y',      # 02-11-2004, 12-24-2003\n",
    "            '%m-%d-%y',      # 01-28-2003\n",
    "            '%m %d %Y',      # 06 29 2005\n",
    "            '%B %d, %Y',     # January 17, 2005, November 9, 2002\n",
    "            '%b %d, %Y',     # May 5th 2004\n",
    "            '%B %dth, %Y',   # July 19th, 2003\n",
    "            '%B %drd, %Y',   # October 23rd, 2005\n",
    "            '%d %B %Y',      # 18 JAN 2024, 10 October 2002\n",
    "            '%B %d %Y',      # June 19 2004\n",
    "            '%Y'             # 2005, 2003\n",
    "        ]\n",
    "        \n",
    "        parsed_dates = pd.Series(index=date_series.index, dtype='datetime64[ns]')\n",
    "        \n",
    "        for idx, date_str in date_series.dropna().items():\n",
    "            if pd.isna(parsed_dates[idx]):\n",
    "                # Clean common suffixes and formatting\n",
    "                clean_date = str(date_str).strip()\n",
    "                clean_date = clean_date.replace('th,', ',').replace('rd,', ',').replace('nd,', ',').replace('st,', ',')\n",
    "                clean_date = clean_date.replace('th ', ' ').replace('rd ', ' ').replace('nd ', ' ').replace('st ', ' ')\n",
    "                \n",
    "                # Try each format\n",
    "                for fmt in formats:\n",
    "                    try:\n",
    "                        parsed_date = pd.to_datetime(clean_date, format=fmt)\n",
    "                        parsed_dates[idx] = parsed_date\n",
    "                        break\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                # If still not parsed, try pandas' flexible parser as last resort\n",
    "                if pd.isna(parsed_dates[idx]):\n",
    "                    try:\n",
    "                        parsed_dates[idx] = pd.to_datetime(clean_date, errors='coerce')\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        return parsed_dates\n",
    "    \n",
    "    # Parse birth dates\n",
    "    df_copy['birth_date'] = parse_birth_dates(df_copy['Q26_clean'])\n",
    "    \n",
    "    # Ensure StartDate is datetime (it's already in the dataframe)\n",
    "    df_copy['StartDate'] = pd.to_datetime(df_copy['StartDate'], errors='coerce')\n",
    "    \n",
    "    # Calculate age for each participant using their individual StartDate\n",
    "    df_copy['age'] = (df_copy['StartDate'] - df_copy['birth_date']).dt.days / 365.25\n",
    "    \n",
    "    # Generate results\n",
    "    total_responses = len(df_copy)\n",
    "    valid_birth_dates = df_copy['birth_date'].notna().sum()\n",
    "    valid_start_dates = df_copy['StartDate'].notna().sum()\n",
    "    valid_ages = df_copy['age'].dropna()\n",
    "    \n",
    "    failed_to_parse_birth = df_copy['Q26_clean'].notna().sum() - valid_birth_dates\n",
    "    declined_or_missing_birth = df_copy['Q26_clean'].isna().sum()\n",
    "    missing_start_dates = total_responses - valid_start_dates\n",
    "    \n",
    "    results = {\n",
    "        'total_responses': total_responses,\n",
    "        'valid_birth_dates': valid_birth_dates,\n",
    "        'valid_start_dates': valid_start_dates,\n",
    "        'failed_to_parse_birth': failed_to_parse_birth,\n",
    "        'declined_or_missing_birth': declined_or_missing_birth,\n",
    "        'missing_start_dates': missing_start_dates,\n",
    "        'processed_df': df_copy\n",
    "    }\n",
    "    \n",
    "    if len(valid_ages) > 0:\n",
    "        # Identify and exclude the 1-year-old outlier\n",
    "        one_year_old = df_copy[df_copy['age'] < 2]  # Find anyone under 2 years old\n",
    "        if len(one_year_old) > 0:\n",
    "            print(f\"Found {len(one_year_old)} participant(s) under 2 years old - excluding from analysis:\")\n",
    "            print(one_year_old[['id', 'Q26', 'Q26_clean', 'birth_date', 'StartDate', 'age']])\n",
    "            \n",
    "            # Exclude the 1-year-old from age calculations\n",
    "            df_copy_clean = df_copy[df_copy['age'] >= 2].copy()\n",
    "            valid_ages_clean = df_copy_clean['age'].dropna()\n",
    "            \n",
    "            # Use cleaned ages for statistics\n",
    "            if len(valid_ages_clean) > 0:\n",
    "                results.update({\n",
    "                    'age_mean': valid_ages_clean.mean(),\n",
    "                    'age_sd': valid_ages_clean.std(),\n",
    "                    'age_min': valid_ages_clean.min(),\n",
    "                    'age_max': valid_ages_clean.max(),\n",
    "                    'n_valid_ages': len(valid_ages_clean),\n",
    "                    'excluded_1_year_old': True\n",
    "                })\n",
    "                results['processed_df'] = df_copy_clean\n",
    "            else:\n",
    "                # Fallback to original if no valid ages after exclusion\n",
    "                results.update({\n",
    "                    'age_mean': valid_ages.mean(),\n",
    "                    'age_sd': valid_ages.std(),\n",
    "                    'age_min': valid_ages.min(),\n",
    "                    'age_max': valid_ages.max(),\n",
    "                    'n_valid_ages': len(valid_ages)\n",
    "                })\n",
    "        else:\n",
    "            # No outliers found, use all valid ages\n",
    "            results.update({\n",
    "                'age_mean': valid_ages.mean(),\n",
    "                'age_sd': valid_ages.std(),\n",
    "                'age_min': valid_ages.min(),\n",
    "                'age_max': valid_ages.max(),\n",
    "                'n_valid_ages': len(valid_ages)\n",
    "            })\n",
    "        \n",
    "        # Show problematic entries\n",
    "        problematic_birth = df_copy[df_copy['birth_date'].isna() & df_copy['Q26_clean'].notna()]\n",
    "        if len(problematic_birth) > 0:\n",
    "            results['problematic_birth_entries'] = problematic_birth['Q26_clean'].unique()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Process both datasets\n",
    "print(\"=\"*60)\n",
    "print(\"PILOT 5 RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pilot5_results = process_birth_dates_with_start_dates(filtered_demo_pilot5)\n",
    "\n",
    "print(f\"Total responses: {pilot5_results['total_responses']}\")\n",
    "print(f\"Valid birth dates parsed: {pilot5_results['valid_birth_dates']}\")\n",
    "print(f\"Valid start dates: {pilot5_results['valid_start_dates']}\")\n",
    "print(f\"Failed to parse birth dates: {pilot5_results['failed_to_parse_birth']}\")\n",
    "print(f\"Declined or missing birth dates: {pilot5_results['declined_or_missing_birth']}\")\n",
    "print(f\"Missing start dates: {pilot5_results['missing_start_dates']}\")\n",
    "\n",
    "if 'age_mean' in pilot5_results:\n",
    "    excluded_note = \" (excluding 1-year-old outlier)\" if pilot5_results.get('excluded_1_year_old', False) else \"\"\n",
    "    print(f\"\\nAge Statistics{excluded_note} (n = {pilot5_results['n_valid_ages']}):\")\n",
    "    print(f\"Mean age: {pilot5_results['age_mean']:.1f} years\")\n",
    "    print(f\"SD: {pilot5_results['age_sd']:.1f}\")\n",
    "    print(f\"Range: {pilot5_results['age_min']:.0f}–{pilot5_results['age_max']:.0f}\")\n",
    "    \n",
    "    # Demographic format\n",
    "    print(f\"\\nDemographic format:\")\n",
    "    print(f\"(M age = {pilot5_results['age_mean']:.1f} years, SD = {pilot5_results['age_sd']:.1f}, range = {pilot5_results['age_min']:.0f}–{pilot5_results['age_max']:.0f})\")\n",
    "\n",
    "if 'problematic_birth_entries' in pilot5_results:\n",
    "    print(f\"\\nProblematic birth date entries:\")\n",
    "    print(pilot5_results['problematic_birth_entries'])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PILOT 6 RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pilot6_results = process_birth_dates_with_start_dates(filtered_demo_pilot6)\n",
    "\n",
    "print(f\"Total responses: {pilot6_results['total_responses']}\")\n",
    "print(f\"Valid birth dates parsed: {pilot6_results['valid_birth_dates']}\")\n",
    "print(f\"Valid start dates: {pilot6_results['valid_start_dates']}\")\n",
    "print(f\"Failed to parse birth dates: {pilot6_results['failed_to_parse_birth']}\")\n",
    "print(f\"Declined or missing birth dates: {pilot6_results['declined_or_missing_birth']}\")\n",
    "print(f\"Missing start dates: {pilot6_results['missing_start_dates']}\")\n",
    "\n",
    "if 'age_mean' in pilot6_results:\n",
    "    excluded_note = \" (excluding 1-year-old outlier)\" if pilot6_results.get('excluded_1_year_old', False) else \"\"\n",
    "    print(f\"\\nAge Statistics{excluded_note} (n = {pilot6_results['n_valid_ages']}):\")\n",
    "    print(f\"Mean age: {pilot6_results['age_mean']:.1f} years\")\n",
    "    print(f\"SD: {pilot6_results['age_sd']:.1f}\")\n",
    "    print(f\"Range: {pilot6_results['age_min']:.0f}–{pilot6_results['age_max']:.0f}\")\n",
    "    \n",
    "    # Demographic format\n",
    "    print(f\"\\nDemographic format:\")\n",
    "    print(f\"(M age = {pilot6_results['age_mean']:.1f} years, SD = {pilot6_results['age_sd']:.1f}, range = {pilot6_results['age_min']:.0f}–{pilot6_results['age_max']:.0f})\")\n",
    "\n",
    "if 'problematic_birth_entries' in pilot6_results:\n",
    "    print(f\"\\nProblematic birth date entries:\")\n",
    "    print(pilot6_results['problematic_birth_entries'])\n",
    "\n",
    "# Store processed dataframes for further use\n",
    "filtered_demo_pilot5_with_ages = pilot5_results['processed_df']\n",
    "filtered_demo_pilot6_with_ages = pilot6_results['processed_df']\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Pilot 5: {pilot5_results.get('n_valid_ages', 0)} valid ages from {pilot5_results['total_responses']} responses\")\n",
    "print(f\"Pilot 6: {pilot6_results.get('n_valid_ages', 0)} valid ages from {pilot6_results['total_responses']} responses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f89ab16-e6fb-481c-ab8d-2d11f751315f",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
